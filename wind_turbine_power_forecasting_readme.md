# ğŸŒ¬ï¸ How I Built a Wind Turbine Power Forecasting Model (A Beginnerâ€‘Friendly Data Science Story)

If youâ€™ve ever wondered how **raw weather data** turns into **accurate power forecasts**, this project is my attempt to show that journey â€” step by step, without skipping the thinking.

This is not just a notebook.
Itâ€™s a **story of how a Data Scientist approaches a real-world energy forecasting problem**.

Whether youâ€™re a beginner, a Kaggle learner, or preparing for interviews, my goal is simple:

> By the end of this project, you should understand **what was done, why it was done, and how you can do it yourself**.

---

## ğŸ§© The Problem I Wanted to Solve

Wind energy depends heavily on nature â€” and nature is noisy.

Given historical data about:
- Wind speed
- Wind direction
- Temperature
- Humidity
- Time

ğŸ‘‰ **Can we predict how much power a wind turbine will generate in the future?**

This makes the problem:
- A **regression problem** (predicting a continuous value)
- With a strong **time-series component** (past affects the future)

---

## ğŸ“‚ Project Structure (Simple & Intentional)

```
Wind_Turbine/
â”‚
â”œâ”€â”€ wind-power-forecasting.ipynb   # The full story lives here
â”œâ”€â”€ xgboost_forecast.pkl           # Trained model (ready for reuse)
â”œâ”€â”€ model_features.pkl             # Features used during training
â”œâ”€â”€ README.md                      # Youâ€™re reading it now
```

I intentionally kept the repo minimal so learners focus on **thinking**, not folder chaos.

---

## ğŸ§  Step 1: Setting Up the Tools

Before touching the data, I loaded the tools every Data Scientist relies on:

- **Pandas & NumPy** â†’ for data handling
- **Matplotlib, Seaborn, Plotly** â†’ to *see* patterns, not guess
- **Scikit-learn** â†’ modeling and evaluation
- **XGBoost** â†’ a powerful real-world ML model
- **Statsmodels** â†’ time series analysis

ğŸ‘‰ Lesson: *Good tools donâ€™t make you smart â€” knowing when to use them does.*

---

## ğŸ“Š Step 2: Meeting the Data for the First Time

The dataset came as two files:
- **Train.csv** â€“ historical data
- **Test.csv** â€“ future periods

First things I checked:
- Shape of the data
- Column names
- Data types

Why?

> Because many projects fail in the first 10 minutes due to careless data loading.

---

## ğŸ” Step 3: Asking the Right Questions About Data

Before modeling, I asked:

- Are there missing values?
- Are sensor readings noisy?
- Do values make physical sense?

Using:
- `.info()`
- `.isnull()`
- `.describe()`

I built a **numerical intuition** of the dataset.

ğŸ‘‰ This step tells you *what kind of mess youâ€™re dealing with*.

---

## â° Step 4: Respecting Time (Very Important)

Time series data is unforgiving.

So I:
- Converted the `Time` column to datetime
- Sorted everything chronologically

Why?

> If time order is wrong, even the best model becomes useless.

---

## ğŸ“ˆ Step 5: Visualizing Reality

I plotted:
- Power generation over time
- Wind speed distributions
- Correlations between features

These plots revealed:
- Daily patterns
- Strong dependency on wind speed
- Noise caused by sensors

ğŸ‘‰ Visuals help you *see the physics behind the data*.

---

## ğŸ§¹ Step 6: Cleaning the Noise

Real-world data is messy â€” especially sensor data.

So I:
- Interpolated missing values using time logic
- Clipped extreme outliers (1%â€“99%)

Why not delete everything?

> Because in energy data, extremes often matter.

---

## ğŸ› ï¸ Step 7: Turning Raw Data into Intelligence (Feature Engineering)

This is where the project truly comes alive.

### ğŸ•’ Time-Based Features
I extracted:
- Hour
- Day
- Month
- Weekday

Why?

> Power demand and wind patterns follow human and natural cycles.

---

### âª Lag Features (Memory of the Past)

I added:
- Power 1 hour ago
- Power 24 hours ago

This teaches the model:

> *What happened recently influences what happens next.*

---

### ğŸ“Š Rolling Statistics (Smoothing the Chaos)

- 24-hour rolling mean
- 7-day rolling mean

These capture:
- Short-term trends
- Weekly seasonality

---

### ğŸŒ¬ï¸ Physics-Inspired Thinking

Since:

> Wind power âˆ (wind speed)Â³

I created features that respect **real-world physics**, not just math.

---

### ğŸ”„ Cyclical Encoding

Time is circular, not linear.

So instead of treating hour 23 and 0 as far apart, I used:
- Sine
- Cosine transformations

ğŸ‘‰ This small trick massively improves learning.

---

## âœ‚ï¸ Step 8: Handling NA Values After Features

Lag and rolling features naturally create missing rows.

Instead of forcing values, I:
- Dropped only the unavoidable initial rows

Clean, honest data beats fake completeness.

---

## ğŸ”¬ Step 9: Understanding the Time Series Itself

I decomposed the power signal into:
- Trend
- Seasonality
- Residual noise

Then ran the **Augmented Dickey-Fuller test** to check stationarity.

ğŸ‘‰ This step improves *conceptual clarity*, even if the model doesnâ€™t strictly need it.

---

## ğŸ”€ Step 10: Train-Test Split (Done the Right Way)

Instead of random splitting, I used:
- First 80% â†’ training
- Last 20% â†’ testing

Why?

> In forecasting, the future must remain unseen.

---

## ğŸ¤– Step 11: Modeling Strategy

### Baseline: Linear Regression
- Simple
- Interpretable
- Sets a performance floor

### Main Model: XGBoost Regressor
- Handles non-linearity
- Works brilliantly on tabular data
- Industry-proven

---

## ğŸ“ Step 12: Measuring Success

I evaluated models using:
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)
- RÂ² Score

Each metric answers a different business question.

---

## ğŸ“Š Step 13: Visual Validation

I plotted:
- Actual vs Predicted power

This answered the most important question:

> *Can I trust this model in the real world?*

---

## ğŸ” Step 14: Feature Importance

Using XGBoostâ€™s feature importance, I identified:
- Which signals matter most
- Which features drive decisions

This builds **explainability and confidence**.

---

## ğŸ’¾ Step 15: Saving the Work (Like a Professional)

I saved:
- The trained model
- The exact feature list

Why?

> A model that canâ€™t be reused is just an experiment.

---

## ğŸ”® Step 16: Looking Ahead

Possible next steps:
- Hyperparameter tuning
- Deep learning (LSTM / Transformers)
- Probabilistic forecasting
- API deployment

---

## ğŸ Final Thoughts

This project reflects how **real Data Science actually works**:

âœ” Think before coding
âœ” Respect time
âœ” Engineer features thoughtfully
âœ” Validate visually
âœ” Save for reuse

If you truly understand this notebook, you are no longer a beginner â€” youâ€™re becoming an **applied Data Scientist**.

Happy forecasting ğŸš€

